{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# useing this variable for saving models and summaries\n",
    "exp_name = \"DWN_Wmultitask_8_opp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from hdf5storage import savemat\n",
    "import hickle \n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.wavelet_conv_model as wavelet_conv_model\n",
    "import training\n",
    "import evaluation.nn_eval_multitask as nn_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "data_path= '../data/opp8.hkl'\n",
    "with open(data_path, 'r') as fin:\n",
    "    data = hickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data['train_data']\n",
    "validation_data = data['validation_data']\n",
    "test_data = data['test_data']\n",
    "\n",
    "train_gt = data['train_gt']\n",
    "validation_gt = data['validation_gt']\n",
    "test_gt = data['test_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((691, 1024, 77), (691, 1024, 19))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119, 1024, 77), (119, 1024, 19))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, test_gt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "n_variables = 77\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "wavelet_levels = 8    #number of wavelet layer to have in the network\n",
    "convolution_levels = 3    #number of convolution to have in the network\n",
    "pooling_stride = [2, 2, 2]\n",
    "weights_shape = [[5, n_variables, 32],\n",
    "                 [5, 32, 32],\n",
    "                 [5, 32, 32]]\n",
    "bias_shape = [32, 32, 32]\n",
    "wavelet_weights_shape = [[5, n_variables, n_variables]]    #high_pass and low_pass dimensions\n",
    "activation = tf.nn.relu\n",
    "n_classes = 19\n",
    "\n",
    "##positive weight for weighted cross entropy\n",
    "s = train_gt.shape\n",
    "resolution = np.prod(pooling_stride)\n",
    "pooled_gt = np.reshape(train_gt[:,:(s[0]*s[1]/resolution)*resolution,:], (s[0]*(s[1]/resolution), resolution, s[2])).max(axis=1)\n",
    "pos_weight = (1.0 - pooled_gt.mean(axis = 0)) / pooled_gt.mean(axis=0)\n",
    "\n",
    "variables_weights = np.ones((n_classes,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691, 1024, 77)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.36565482,  48.46756152,  47.65126513,  50.0669746 ,\n",
       "        49.94930876,  40.02411874,  41.52307692,  58.84303112,\n",
       "        63.4664723 ,  75.37996546,  86.74603175,  80.14495413,\n",
       "        87.27145709,  69.42038217,  68.86413902,  43.71587462,\n",
       "        13.05721551,  58.2021419 ,  10.05323669])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_path = '../summary/' + exp_name \n",
    "checkpoint_path = '../model/' + exp_name + '/checkpoint' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = wavelet_conv_model.Model(n_variables = n_variables,\n",
    "                                 learning_rate = learning_rate,\n",
    "                                 n_classes = n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.build_neural_wavelet_layer(pos_weight = pos_weight, \n",
    "                                 learning_rate = learning_rate,\n",
    "                                 wavelet_levels = wavelet_levels,    \n",
    "                                 convolution_levels = convolution_levels,    \n",
    "                                 pooling_stride = pooling_stride,     \n",
    "                                 weights_shape = weights_shape,\n",
    "                                 bias_shape = bias_shape,\n",
    "                                 wavelet_weights_shape = wavelet_weights_shape,    \n",
    "                                 activation = activation,\n",
    "                                 trainable_wavelet = True,\n",
    "                                 trainable_conv = True,\n",
    "                                 trainable_last = True,\n",
    "                                 variables_weights = variables_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = training.Trainer(model = model,\n",
    "                    data_train = train_data,\n",
    "                    ground_truth_train = train_gt,\n",
    "                    data_validation = test_data,\n",
    "                    ground_truth_validation = test_gt,\n",
    "                    sess = sess,\n",
    "                    summary_path = summary_path,\n",
    "                    batch_size = batch_size,\n",
    "                    global_step = 0,\n",
    "                    eval_type = 'multitask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch Evaluation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.060 vs. 0.060\n",
      "F1 = 0.100 vs. 0.091\n",
      "Accuracy = 0.003 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.073 vs. 0.093\n",
      "F1 = 0.181 vs. 0.175\n",
      "Precision = 0.100 vs. 0.096\n",
      "Recall = 0.967 vs. 0.970\n",
      "Validation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.059 vs. 0.059\n",
      "F1 = 0.082 vs. 0.081\n",
      "Accuracy = 0.009 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.036 vs. 0.050\n",
      "F1 = 0.104 vs. 0.097\n",
      "Precision = 0.055 vs. 0.051\n",
      "Recall = 0.987 vs. 0.901\n",
      "Minibatch Loss= 1.512073\n",
      "Train Batch Evaluation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.518 vs. 0.062\n",
      "F1 = 0.547 vs. 0.091\n",
      "Accuracy = 0.391 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.197 vs. 0.103\n",
      "F1 = 0.289 vs. 0.183\n",
      "Precision = 0.207 vs. 0.101\n",
      "Recall = 0.480 vs. 0.963\n",
      "Validation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.275 vs. 0.059\n",
      "F1 = 0.369 vs. 0.081\n",
      "Accuracy = 0.346 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.149 vs. 0.047\n",
      "F1 = 0.240 vs. 0.097\n",
      "Precision = 0.164 vs. 0.051\n",
      "Recall = 0.449 vs. 0.992\n",
      "Minibatch Loss= 0.454655\n",
      "Train Batch Evaluation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.653 vs. 0.063\n",
      "F1 = 0.652 vs. 0.093\n",
      "Accuracy = 0.738 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.239 vs. 0.103\n",
      "F1 = 0.334 vs. 0.189\n",
      "Precision = 0.224 vs. 0.105\n",
      "Recall = 0.658 vs. 0.934\n",
      "Validation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.384 vs. 0.059\n",
      "F1 = 0.458 vs. 0.081\n",
      "Accuracy = 0.715 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.161 vs. 0.053\n",
      "F1 = 0.243 vs. 0.097\n",
      "Precision = 0.167 vs. 0.051\n",
      "Recall = 0.449 vs. 0.990\n",
      "Minibatch Loss= 0.299652\n",
      "Train Batch Evaluation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.733 vs. 0.062\n",
      "F1 = 0.725 vs. 0.092\n",
      "Accuracy = 0.783 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.249 vs. 0.089\n",
      "F1 = 0.348 vs. 0.161\n",
      "Precision = 0.251 vs. 0.088\n",
      "Recall = 0.569 vs. 0.998\n",
      "Validation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.408 vs. 0.058\n",
      "F1 = 0.473 vs. 0.080\n",
      "Accuracy = 0.746 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.174 vs. 0.054\n",
      "F1 = 0.257 vs. 0.104\n",
      "Precision = 0.166 vs. 0.058\n",
      "Recall = 0.561 vs. 0.499\n",
      "Minibatch Loss= 0.206577\n",
      "Train Batch Evaluation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.768 vs. 0.061\n",
      "F1 = 0.758 vs. 0.090\n",
      "Accuracy = 0.852 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.270 vs. 0.097\n",
      "F1 = 0.360 vs. 0.170\n",
      "Precision = 0.277 vs. 0.099\n",
      "Recall = 0.514 vs. 0.598\n",
      "Validation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.429 vs. 0.059\n",
      "F1 = 0.495 vs. 0.080\n",
      "Accuracy = 0.824 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.168 vs. 0.052\n",
      "F1 = 0.249 vs. 0.099\n",
      "Precision = 0.175 vs. 0.052\n",
      "Recall = 0.431 vs. 0.823\n",
      "Minibatch Loss= 0.202245\n",
      "Train Batch Evaluation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.806 vs. 0.063\n",
      "F1 = 0.791 vs. 0.093\n",
      "Accuracy = 0.833 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.303 vs. 0.091\n",
      "F1 = 0.388 vs. 0.182\n",
      "Precision = 0.284 vs. 0.100\n",
      "Recall = 0.612 vs. 0.998\n",
      "Validation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.441 vs. 0.059\n",
      "F1 = 0.503 vs. 0.077\n",
      "Accuracy = 0.793 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.176 vs. 0.048\n",
      "F1 = 0.271 vs. 0.097\n",
      "Precision = 0.184 vs. 0.051\n",
      "Recall = 0.509 vs. 1.000\n",
      "Minibatch Loss= 0.167872\n",
      "Train Batch Evaluation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.817 vs. 0.063\n",
      "F1 = 0.802 vs. 0.094\n",
      "Accuracy = 0.847 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.326 vs. 0.099\n",
      "F1 = 0.414 vs. 0.181\n",
      "Precision = 0.314 vs. 0.099\n",
      "Recall = 0.608 vs. 1.000\n",
      "Validation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.440 vs. 0.060\n",
      "F1 = 0.496 vs. 0.085\n",
      "Accuracy = 0.801 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.180 vs. 0.053\n",
      "F1 = 0.270 vs. 0.103\n",
      "Precision = 0.196 vs. 0.057\n",
      "Recall = 0.434 vs. 0.517\n",
      "Minibatch Loss= 0.146978\n",
      "Train Batch Evaluation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.838 vs. 0.061\n",
      "F1 = 0.830 vs. 0.092\n",
      "Accuracy = 0.857 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.335 vs. 0.094\n",
      "F1 = 0.420 vs. 0.177\n",
      "Precision = 0.321 vs. 0.101\n",
      "Recall = 0.610 vs. 0.744\n",
      "Validation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.454 vs. 0.058\n",
      "F1 = 0.504 vs. 0.077\n",
      "Accuracy = 0.796 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.174 vs. 0.053\n",
      "F1 = 0.263 vs. 0.100\n",
      "Precision = 0.170 vs. 0.055\n",
      "Recall = 0.584 vs. 0.571\n",
      "Minibatch Loss= 0.127052\n",
      "Train Batch Evaluation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.870 vs. 0.062\n",
      "F1 = 0.852 vs. 0.088\n",
      "Accuracy = 0.884 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.336 vs. 0.090\n",
      "F1 = 0.408 vs. 0.161\n",
      "Precision = 0.304 vs. 0.088\n",
      "Recall = 0.619 vs. 0.986\n",
      "Validation\n",
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.443 vs. 0.060\n",
      "F1 = 0.489 vs. 0.079\n",
      "Accuracy = 0.814 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.178 vs. 0.056\n",
      "F1 = 0.260 vs. 0.103\n",
      "Precision = 0.187 vs. 0.056\n",
      "Recall = 0.426 vs. 0.745\n",
      "Minibatch Loss= 0.113741\n"
     ]
    }
   ],
   "source": [
    "trainer.train(max_iter = 20000,\n",
    "                train_eval_step = 100, \n",
    "                validation_eval_step = 100,\n",
    "                display_step = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save the model\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, checkpoint_path, global_step=trainer.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../model/DWN_activity_multitask_64_opp/checkpoint-20000\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "saver = tf.train.Saver()\n",
    "#saver.restore(sess, \"../model\" + \"/CNN7002_Gleam\" + \"/CNN7002_Gleam\")\n",
    "saver.restore(sess, '../model/DWN_activity_multitask_64_opp/checkpoint-20000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVITY RECOGNITION\n",
      "AUC = 0.576 vs. 0.063\n",
      "F1 = 0.599 vs. 0.089\n",
      "Accuracy = 0.898 vs. 0.056\n",
      "CHANGE DETECTION\n",
      "AUC = 0.386 vs. 0.102\n",
      "F1 = 0.453 vs. 0.183\n",
      "Precision = 0.389 vs. 0.101\n",
      "Recall = 0.541 vs. 0.989\n"
     ]
    }
   ],
   "source": [
    "#This is the model evaluation on test dataset\n",
    "result = nn_eval.evaluate_model (model, sess, test_data, test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = nn_eval.deploy(model, sess, test_data, test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shape of probability_change is (batch size, T, num_classes)\n",
    "#since num_classes = 1 we squeeze that axis\n",
    "#probability_change = np.squeeze(out, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savemat('../poc/poc'+exp_name+'.mat', {'poc':out[:,:,-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119, 32, 19)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Anaconca with Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
