{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pickle \n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import data_utils_Gleam as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "data_path = '/data2/PHI/PHI_GLASS_public/PublishableData'\n",
    "#list of dictionaries\n",
    "data = data_utils.load_data(data_path,  range(1101, 1139))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_range = range(38)\n",
    "random.Random(4).shuffle(subject_range)\n",
    "train_sub = subject_range[:30]\n",
    "#valid_sub = subject_range[20:23]\n",
    "test_sub = subject_range[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = [data[i] for i in train_sub]\n",
    "#data_valid = [data[i] for i in valid_sub]\n",
    "data_test = [data[i] for i in test_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1412289879112 1412297209269\n",
      "1416425272791 1416432451726\n",
      "1413478893180 1413486008523\n",
      "1413571209732 1413578148207\n",
      "1413391939568 1413399213785\n",
      "1407340649187 1407348083484\n",
      "1405958662457 1405966050897\n",
      "1413903388283 1413910632268\n",
      "1414603026033 1414610265601\n",
      "1411574538361 1411581813212\n",
      "1413466026745 1413473268810\n",
      "1413392755456 1413400247994\n",
      "1406131222569 1406138444671\n",
      "1415818889708 1415826038361\n",
      "1409161304244 1409168762951\n",
      "1408986167043 1408993288274\n",
      "1408471372831 1408478529660\n",
      "1412968225286 1412975698440\n",
      "1415818884380 1415826047793\n",
      "1412611373766 1412618602407\n",
      "1411148791035 1411156498431\n",
      "1412179376997 1412186707141\n",
      "1412780496193 1412787706891\n",
      "1415038580036 1415045759891\n",
      "1414772046164 1414779069763\n",
      "1406561452505 1406568630002\n",
      "1406832980526 1406840167094\n",
      "1410969126107 1410976355201\n",
      "1406818792411 1406826224021\n",
      "1412786012734 1412793360916\n",
      "1412971344750 1412978764941\n",
      "1413484541672 1413491885072\n",
      "1410372239293 1410379460114\n",
      "1406214527485 1406221825248\n",
      "1406736098920 1406743229866\n",
      "1410881648285 1410888963677\n",
      "1406215173364 1406222363888\n",
      "1407266270688 1407273301145\n"
     ]
    }
   ],
   "source": [
    "processed_train_data, train_data_info = data_utils.pre_process(data_train, down_factor = 100)\n",
    "#processed_valid_data, valid_data_info = data_utils.pre_process(data_valid, down_factor = 100)\n",
    "processed_test_data, test_data_info = data_utils.pre_process(data_test, down_factor = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading ground truth\n",
    "\n",
    "#trin_gt is a list contains time points of ground truth for each subject of train data\n",
    "train_gt = data_utils.load_groundtruth(data_path,\n",
    "                                       train_sub,\n",
    "                                       train_data_info)\n",
    "test_gt = data_utils.load_groundtruth(data_path,\n",
    "                                      test_sub,\n",
    "                                      test_data_info)\n",
    "\n",
    "#list of time series length for each subject of train data\n",
    "length_train = [processed_train_data[i].shape[0] for i in range(len(train_sub))]\n",
    "length_test = [processed_test_data[i].shape[0] for i in range(len(test_sub))]\n",
    "\n",
    "#probability of being change for time steps\n",
    "processed_train_gt = data_utils.pre_process_ground_truth(train_gt,\n",
    "                                                        length_train,\n",
    "                                                        sigma = 10)\n",
    "processed_test_gt = data_utils.pre_process_ground_truth(test_gt,\n",
    "                                                        length_test,\n",
    "                                                        sigma = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sliding window\n",
    "#parameters\n",
    "\n",
    "window_size = 1024\n",
    "stride = 800\n",
    "_, data_stacked_train= data_utils.slide_window(processed_train_data,\n",
    "                                                    window_size,\n",
    "                                                    stride,\n",
    "                                                    num_dim_expand=0)\n",
    "\n",
    "_, gt_stacked_train_probability = data_utils.slide_window(processed_train_gt,\n",
    "                                                    window_size,\n",
    "                                                    stride,\n",
    "                                                    num_dim_expand=0)\n",
    "\n",
    "\n",
    "\n",
    "_, data_stacked_test = data_utils.slide_window(processed_test_data,\n",
    "                                                   window_size,\n",
    "                                                   stride,\n",
    "                                                   num_dim_expand=0)\n",
    "\n",
    "_, gt_stacked_test_probability = data_utils.slide_window(processed_test_gt,\n",
    "                                                   window_size,\n",
    "                                                   stride,\n",
    "                                                   num_dim_expand=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data and ground truth for training dataset\n",
    "** subsampling negative samples in order to have same number of positive and negative samples **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(gt_stacked_train.shape[0]):\n",
    "pos_idx_train = np.where(gt_stacked_train_probability.max(axis=1)!=0.0)[0]\n",
    "#all_neg_idx_train = np.where(gt_stacked_train_probability.max(axis=1)==0.0)[0]\n",
    "#all_neg_idx_train = [i for i in range(gt_stacked_train.shape[0]) if i not in pos_idx_train]\n",
    "\n",
    "#neg_idx_train = np.random.choice(all_neg_idx_train,\n",
    "\n",
    "#                                pos_idx_train.shape[0],\n",
    "#                                 replace = False)\n",
    "\n",
    "#concatenate positive and negative idexes for choosing from data train\n",
    "#idx_train = np.concatenate((pos_idx_train, neg_idx_train), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subsample_train = data_stacked_train[pos_idx_train]\n",
    "gt_probability_subsample_train = gt_stacked_train_probability[pos_idx_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data and ground truth for test and valid dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_idx_test = np.where(gt_stacked_test_probability.max(axis=1)!=0.0)[0]\n",
    "data_subsample_test = data_stacked_test[pos_idx_test]\n",
    "gt_probability_subsample_test = gt_stacked_test_probability[pos_idx_test]\n",
    "#gt_index_subsample_test = gt_test[pos_idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((525, 1024, 19), (525, 1024))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subsample_train.shape, gt_probability_subsample_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129, 1024, 19), (129, 1024))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subsample_test.shape, gt_probability_subsample_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gt[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['train_data'] = data_subsample_train\n",
    "data['train_gt'] = gt_probability_subsample_train\n",
    "\n",
    "#data['validation_data'] = data_stacked_validation\n",
    "#data['validation_gt'] = gt_stacked_validation\n",
    "\n",
    "data['test_data'] = data_subsample_test\n",
    "data['test_gt'] = gt_probability_subsample_test\n",
    "\n",
    "data['index_of_changes_test'] = test_gt\n",
    "data['index_of_changes_train'] = train_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = '/data2/data/zebrahim/Gleam/'\n",
    "with open(path_to_save+'Gleam1.p', 'w') as fout:\n",
    "    pickle.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconca with Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
