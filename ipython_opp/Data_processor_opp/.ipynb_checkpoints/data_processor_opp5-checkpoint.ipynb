{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "import simplejson as json\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import data_utils_opp as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "reading file 1 of 19\n",
      "reading file 2 of 19\n",
      "reading file 3 of 19\n",
      "reading file 4 of 19\n",
      "reading file 5 of 19\n",
      "reading file 6 of 19\n",
      "reading file 7 of 19\n",
      "reading file 8 of 19\n",
      "reading file 9 of 19\n",
      "reading file 10 of 19\n",
      "reading file 11 of 19\n",
      "reading file 12 of 19\n",
      "reading file 13 of 19\n",
      "reading file 14 of 19\n",
      "reading file 15 of 19\n",
      "reading file 16 of 19\n",
      "reading file 17 of 19\n",
      "reading file 18 of 19\n",
      "reading file 19 of 19\n",
      "reading file 1 of 1\n",
      "reading file 1 of 4\n",
      "reading file 2 of 4\n",
      "reading file 3 of 4\n",
      "reading file 4 of 4\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "data_path = '/data2/data/zebrahim/OpportunityUCIDataset'\n",
    "\n",
    "dr = data_utils.data_reader('opportunity', data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700165, 77), (700165,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.data['training']['inputs'].shape, dr.data['training']['targets'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(dr.data['training']['inputs'] , axis=0)\n",
    "validation_data = np.expand_dims(dr.data['validation']['inputs'] , axis=0)\n",
    "test_data = np.expand_dims(dr.data['test']['inputs'] , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = np.unique(dr.data['training']['targets']).shape[0]\n",
    "train_gt = np.zeros((train_data.shape[1], n_class))\n",
    "\n",
    "for i in range(train_data.shape[1]):\n",
    "    train_gt[i, dr.data['training']['targets'][i]-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_gt = np.zeros((validation_data.shape[1], n_class))\n",
    "\n",
    "for i in range(validation_data.shape[1]):\n",
    "    validation_gt[i, dr.data['validation']['targets'][i]-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gt = np.zeros((test_data.shape[1], n_class))\n",
    "\n",
    "for i in range(test_data.shape[1]):\n",
    "    test_gt[i, dr.data['test']['targets'][i]-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt = np.expand_dims(train_gt , axis=0)\n",
    "validation_gt = np.expand_dims(validation_gt , axis=0)\n",
    "test_gt = np.expand_dims(test_gt , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['train_data'] = train_data\n",
    "data['train_gt'] = train_gt\n",
    "\n",
    "data['validation_data'] = validation_data\n",
    "data['validation_gt'] = validation_gt\n",
    "\n",
    "\n",
    "data['test_data'] =  test_data\n",
    "data['test_gt'] = test_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle\n",
    "path_to_save = '../data/'\n",
    "with open(path_to_save+'opp1.hkl', 'w') as fout:\n",
    "    hickle.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconca with Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
