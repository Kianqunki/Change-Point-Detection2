{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "import simplejson as json\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import data_utils_opp_new_split as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "reading file 1 of 18\n",
      "reading file 2 of 18\n",
      "reading file 3 of 18\n",
      "reading file 4 of 18\n",
      "reading file 5 of 18\n",
      "reading file 6 of 18\n",
      "reading file 7 of 18\n",
      "reading file 8 of 18\n",
      "reading file 9 of 18\n",
      "reading file 10 of 18\n",
      "reading file 11 of 18\n",
      "reading file 12 of 18\n",
      "reading file 13 of 18\n",
      "reading file 14 of 18\n",
      "reading file 15 of 18\n",
      "reading file 16 of 18\n",
      "reading file 17 of 18\n",
      "reading file 18 of 18\n",
      "reading file 1 of 1\n",
      "reading file 1 of 6\n",
      "reading file 2 of 6\n",
      "reading file 3 of 6\n",
      "reading file 4 of 6\n",
      "reading file 5 of 6\n",
      "reading file 6 of 6\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "data_path = '/data2/data/zebrahim/OpportunityUCIDataset'\n",
    "\n",
    "dr = data_utils.data_reader('opportunity', data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((639875, 77), (639875,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.data['training']['inputs'].shape, dr.data['training']['targets'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(dr.data['training']['inputs'] , axis=0)\n",
    "validation_data = np.expand_dims(dr.data['validation']['inputs'] , axis=0)\n",
    "test_data = np.expand_dims(dr.data['test']['inputs'] , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = np.unique(dr.data['training']['targets']).shape[0]\n",
    "train_gt = np.zeros((train_data.shape[1], n_class))\n",
    "\n",
    "for i in range(train_data.shape[1]):\n",
    "    train_gt[i, dr.data['training']['targets'][i]-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_gt = np.zeros((validation_data.shape[1], n_class))\n",
    "\n",
    "for i in range(validation_data.shape[1]):\n",
    "    validation_gt[i, dr.data['validation']['targets'][i]-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gt = np.zeros((test_data.shape[1], n_class))\n",
    "\n",
    "for i in range(test_data.shape[1]):\n",
    "    test_gt[i, dr.data['test']['targets'][i]-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt = np.expand_dims(train_gt , axis=0)\n",
    "validation_gt = np.expand_dims(validation_gt , axis=0)\n",
    "test_gt = np.expand_dims(test_gt , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['train_data'] = train_data\n",
    "data['train_gt'] = train_gt\n",
    "\n",
    "data['validation_data'] = validation_data\n",
    "data['validation_gt'] = validation_gt\n",
    "\n",
    "\n",
    "data['test_data'] =  test_data\n",
    "data['test_gt'] = test_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle\n",
    "path_to_save = '../data/'\n",
    "with open(path_to_save+'opp2.hkl', 'w') as fout:\n",
    "    hickle.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconca with Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
